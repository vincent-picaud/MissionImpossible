#+DATE: [2020-01-08 Wed 14:58]
#+TITLE: Mission : Impossible (self-destructing AD local tapes...)

* What is it?

*Mission : Impossible* is a concise and fast C++17 implementation of automatic
differentiation based on operator overloading. It is adapted for
general purpose small to mid size problems. 

The GitHub repository is https://github.com/vincent-picaud/MissionImpossible.

For repeated calculations it is very easy to define an
auto-destructive local tape, hence the wink to the "Mission:
Impossible" series.

[[file:figures/tape.jpeg][file:./figures/tape.jpeg]]

#+BEGIN_SRC sh :wrap "src cpp :eval never" :results output :exports results
cat $(pwd)/examples/local_tape.cpp
#+END_SRC

#+RESULTS:
#+BEGIN_src cpp :eval never
#include "MissionImpossible/MissionImpossible.hpp"

#include <array>
#include <iostream>

using namespace MissionImpossible;

// A C++ function
template <typename T>
T
Rosenbrock(const std::array<T, 2>& X)
{
  return (1 - X[0]) * (1 - X[0]) + 10 * (X[1] - X[0] * X[0]) * (X[1] - X[0] * X[0]);
}

// A C++ function that adds gradient computation
template <typename T>
T
Rosenbrock(const std::array<T, 2>& X, std::array<T, 2>& grad)
{
  MissionImpossible_Tape<T> local_tape;  // a local thread_local tape

  std::array<AD<T>, 2> ad_X;

  ad_X[0] = X[0];
  ad_X[1] = X[1];

  AD<T> ad_f = Rosenbrock(ad_X);

  Tape_Vector<T> ad_grad_f = gradient(local_tape, ad_f);  // use the local tape for ∇f

  grad[0] = ad_grad_f[ad_X[0]];
  grad[1] = ad_grad_f[ad_X[1]];

  return ad_f.value();

  // here the local tape is destroyed (in fact re-winded to avoid
  // useless new/delete)
}

int
main()
{
  std::array<float, 2> X{3., 4.};

  float f1 = Rosenbrock(X);

  std::cout << "f1  = " << f1 << std::endl;

  std::array<float, 2> grad;

  float f2 = Rosenbrock(X, grad);

  std::cout << "f2  = " << f2 << std::endl;
  std::cout << "∇f2 = [ " << grad[0] << ", " << grad[1] << " ]" << std::endl;
}
#+END_src

prints

#+BEGIN_SRC sh :wrap "src cpp :eval never" :results output :exports results
$(pwd)/build/examples/local_tape
#+END_SRC

#+RESULTS:
#+BEGIN_src cpp :eval never
f1  = 254
f2  = 254
∇f2 = [ 604, -100 ]
#+END_src

This library has been optimized for unstructured (= not vectorized)
first order derivatives. Its speed must be comparable to [[https://github.com/rjhogan/Adept-2][Adept]] as it
relies on the same kind of approach [1].

#+begin_quote
[1], Srajer, Filip, Zuzana Kukelova, and Andrew Fitzgibbon. "A
benchmark of selected algorithmic differentiation tools on some
problems in computer vision and machine learning." Optimization
Methods and Software 33.4-6 (2018): 889-906.
#+end_quote

The library support arbitrary derivatives order but it has not been
optimized for that. By example for second order derivatives the
symmetry ∂ij=∂ji is not taken into account. This leads to redundant
computations. Approaches like [2,3] are more effective in that case.

#+begin_quote
[2], Wang, Mu, Assefaw Gebremedhin, and Alex Pothen. "Capitalizing on
live variables: new algorithms for efficient Hessian computation via
automatic differentiation." Mathematical Programming Computation 8.4
(2016): 393-433.
#+end_quote

#+begin_quote
[3], Gower, Robert Mansel, and Artur L. Gower. "Higher-order reverse
automatic differentiation with emphasis on the third-order."
Mathematical Programming 155.1-2 (2016): 81-103.
#+end_quote

** News

   - [2020-01-07 Tue 12:27] \\
     This a *pre-release* for the curious. Some developments remain to be
     done (implementing special functions, adding examples and benchmarks)
     but the design and API is not expected to change a lot.

* Compilation

The library currently uses the [[https://mesonbuild.com/][meson]] build system.

If you are not familiar with meson, the compilation procedure is as
follows:

#+BEGIN_SRC sh :eval never
git clone https://github.com/vincent-picaud/MissionImpossible.git
cd MissionImpossible/
meson build
cd build
ninja test
#+END_SRC 

** Release

To get an *optimized* version, use:

#+BEGIN_SRC sh :eval never
meson --buildtype=release -Db_ndebug=true build-release
#+END_SRC

* Examples

These examples can be found in the =build/examples/= directory.

** Jacobian example

Illustrates *forward-mode* and *reverse-mode* support. The first one is
convenient to compute the Jacobian column by column. The second one is
effective to compute gradients (or equivalently to compute the
Jacobian row by row).

#+BEGIN_SRC sh :wrap "src cpp :eval never" :results output :exports results
cat $(pwd)/examples/Jacobian.cpp
#+END_SRC

#+RESULTS:
#+BEGIN_src cpp :eval never
#include "MissionImpossible/MissionImpossible.hpp"

#include <iostream>

using namespace MissionImpossible;

int
main()
{
  AD<double> r = 2, theta = 0.1;

  AD<double> y1 = r * cos(theta);
  AD<double> y2 = r * sin(theta);

  //////////////////////////////////
  // Computes Jacobian row by row //
  //////////////////////////////////
  //
  // -> AKA reverse-mode
  //
  std::cout << "Jacobian row by row" << std::endl;

  auto Jacobian_row_y1 = Jacobian_row(y1);  // ∇y1
  auto Jacobian_row_y2 = Jacobian_row(y2);  // ∇y2
  
  std::cout << "∇y1(r,θ) = " << std::setw(20) << Jacobian_row_y1[r] << ", ";
  std::cout << std::setw(20) << Jacobian_row_y1[theta] << std::endl;

  std::cout << "∇y2(r,θ) = " << std::setw(20) << Jacobian_row_y2[r] << ", ";
  std::cout << std::setw(20) << Jacobian_row_y2[theta] << std::endl;

  ////////////////////////////////////////
  // Computes Jacobian column by column //
  ////////////////////////////////////////
  //
  // -> AKA forward-mode
  //
  std::cout << std::endl << "Jacobian column by column" << std::endl;

  auto Jacobian_column_r     = Jacobian_column(r);      // r column
  auto Jacobian_column_theta = Jacobian_column(theta);  // θ column

  std::cout << "∂r y1  = " << std::setw(20) << Jacobian_column_r[y1] << "\t"
            << "∂θ y1  = " << std::setw(20) << Jacobian_column_theta[y1] << std::endl;
  std::cout << "∂r y2  = " << std::setw(20) << Jacobian_column_r[y2] << "\t"
            << "∂θ y2  = " << std::setw(20) << Jacobian_column_theta[y2] << std::endl;
}
#+END_src

prints

#+BEGIN_SRC sh :wrap "example" :results output :exports results
$(pwd)/build/examples/Jacobian
#+END_SRC

#+RESULTS:
#+BEGIN_example
Jacobian row by row
∇y1(r,θ) =             0.995004,            -0.199667
∇y2(r,θ) =            0.0998334,              1.99001

Jacobian column by column
∂r y1  =             0.995004	∂θ y1  =            -0.199667
∂r y2  =            0.0998334	∂θ y2  =              1.99001
#+END_example


** Complex number example

Illustrates complex number support:

#+BEGIN_SRC sh :wrap "src cpp :eval never" :results output :exports results
cat $(pwd)/examples/ad_complex.cpp
#+END_SRC

#+RESULTS:
#+begin_src cpp :eval never
#include "MissionImpossible/MissionImpossible.hpp"

#include <complex>
#include <iostream>

using namespace MissionImpossible;

void
most_efficient() // <- the prefered method 
{
  using T = std::complex<double>;

  AD<T> z0 = T(1, 2), Z;

  Z = 4 * exp(2 * z0 * z0);

  auto dZ = gradient(Z);

  std::cout << " f = " << Z << std::endl;
  std::cout << "df = " << dZ[z0] << std::endl;
}

template <typename F>
void
more_versatile(F f)
{
  AD<double> x(1), y(2);
  std::complex<AD<double>> z0(x, y), Z;

  Z = f(z0);

  AD<double> u = Z.real(), v = Z.imag();

  const auto grad_u = gradient(u);

  // assumes that Z is holomorph
  //
  std::cout << " f = " << Z << std::endl;
  std::cout << "df = " << grad_u[x] << ", ";
  std::cout << -grad_u[y] << std::endl;

  // Cauchy-Riemann
  //
  const auto grad_v = gradient(v);

  std::cout << "--> Cauchy-Riemann check:" << std::endl;
  std::cout << grad_u[x] << " ?= " << grad_v[y] << std::endl;
  std::cout << grad_u[y] << " ?= " << -grad_v[x] << std::endl;
}

int
main()
{
  std::cout << "          f1:   " << std::endl;
  most_efficient();

  //================

  auto f_holomorph     = [](const auto& z) { return 4 * exp(2 * z * z); };
  auto f_not_holomorph = [](const auto& z) { return sqrt(z * conj(z)); };

  std::cout << std::endl << "Holomorph f1:   " << std::endl;
  more_versatile(f_holomorph);

  std::cout << std::endl << "Not holomorph f2: " << std::endl;
  more_versatile(f_not_holomorph);
}
#+end_src

prints:

#+begin_example
         f1:   
 f = (-0.00144263,+0.0098095)
df = (-0.0842465,+0.0276969)

Holomorph f1:   
 f = (-0.00144263,+0.0098095)
df = -0.0842465, +0.0276969
--> Cauchy-Riemann check:
-0.0842465 ?= -0.0842465
-0.0276969 ?= -0.0276969

Not holomorph f2: 
 f = (+2.23607,+0)
df = -0.894427, +1.78885
--> Cauchy-Riemann check:
-0.894427 ?= +0
-1.78885 ?= -0
#+end_example

** Hessian action Hv, directional derivatives

Illustrates Hessian action Hv=∇ <∇f,v> computation:

#+BEGIN_SRC sh :wrap "src cpp :eval never" :results output :exports results
cat $(pwd)/examples/Hv.cpp
#+END_SRC

#+RESULTS:
#+begin_src cpp :eval never
#include "MissionImpossible/MissionImpossible.hpp"

using namespace MissionImpossible;

int
main()
{
  AD<AD<double>> x0(3), x1(4), y;

  y = (1 - x0) * (1 - x0) + 10 * (x1 - x0 * x0) * (x1 - x0 * x0);

  std::cout << "f = " << y << std::endl;

  auto y_gradient = gradient(y);  // Computes ∇f

  std::cout << "∇f= " << y_gradient[x0] << ", ";
  std::cout << y_gradient[x1] << std::endl;

  AD<double> z;

  double v0(5), v1(6);

  z = v0 * y_gradient[x0] + v1 * y_gradient[x1];  // Computes z=<∇f,v>

  auto z_gradient = gradient(z);  // Computes Hv = ∇z = ∇ <∇f,v>

  std::cout << "Hv= " << z_gradient[x0] << ", ";
  std::cout << z_gradient[x1] << std::endl;
}
#+end_src

prints

#+begin_example
f = +254
∇f= +604, -100
Hv= +3890, -480
#+end_example

** Third order example 

Illustrates nested computations support

#+BEGIN_SRC sh :wrap "src cpp :eval never" :results output :exports results
cat $(pwd)/examples/nested.cpp
#+END_SRC

#+RESULTS:
#+begin_src cpp :eval never
#include "MissionImpossible/MissionImpossible.hpp"

#include <iostream>

using namespace MissionImpossible;

template <typename T>
auto
Rosenbrock(const T& x0, const T& x1)
{
  return (1 - x0) * (1 - x0) + 10 * (x1 - x0 * x0) * (x1 - x0 * x0);
}

// Third order demo
int
main()
{
  AD<AD<AD<double>>> x0(3), x1(4), y;

  y = Rosenbrock(x0, x1);

  auto grad = gradient(y);

  auto Hessian_x0_row = gradient(grad[x0]);
  auto Hessian_x1_row = gradient(grad[x1]);

  auto third_order_x0_x0_row = gradient(Hessian_x0_row[x0]);
  auto third_order_x0_x1_row = gradient(Hessian_x0_row[x1]);
  auto third_order_x1_x0_row = gradient(Hessian_x1_row[x0]);
  auto third_order_x1_x1_row = gradient(Hessian_x1_row[x1]);

  std::cout << "f     = " << y << std::endl;
  std::cout << std::endl;
  std::cout << "∂₀f   = " << grad[x0] << std::endl;
  std::cout << "∂₁f   = " << grad[x1] << std::endl;
  std::cout << std::endl;
  std::cout << "∂²₀₀f = " << Hessian_x0_row[x0] << std::endl;
  std::cout << "∂²₀₁f = " << Hessian_x0_row[x1] << std::endl;
  std::cout << "∂²₁₀f = " << Hessian_x1_row[x0] << std::endl;
  std::cout << "∂²₁₁f = " << Hessian_x1_row[x1] << std::endl;
  std::cout << std::endl;
  std::cout << "∂³₀₀₀f = " << third_order_x0_x0_row[x0] << std::endl;
  std::cout << "∂³₀₀₁f = " << third_order_x0_x0_row[x1] << std::endl;
  std::cout << "∂³₀₁₀f = " << third_order_x0_x1_row[x0] << std::endl;
  std::cout << "∂³₀₁₁f = " << third_order_x0_x1_row[x1] << std::endl;
  std::cout << "∂³₁₀₀f = " << third_order_x1_x0_row[x0] << std::endl;
  std::cout << "∂³₁₀₁f = " << third_order_x1_x0_row[x1] << std::endl;
  std::cout << "∂³₁₁₀f = " << third_order_x1_x1_row[x0] << std::endl;
  std::cout << "∂³₁₁₁f = " << third_order_x1_x1_row[x1] << std::endl;
}
#+end_src

which prints
#+begin_example
f     = +254

∂₀f   = +604
∂₁f   = -100

∂²₀₀f = +922
∂²₀₁f = -120
∂²₁₀f = -120
∂²₁₁f = +20

∂³₀₀₀f = +720
∂³₀₀₁f = -40
∂³₀₁₀f = -40
∂³₀₁₁f = +0
∂³₁₀₀f = -40
∂³₁₀₁f = +0
∂³₁₁₀f = +0
∂³₁₁₁f = +0
#+end_example

TODO: benchmark, more (and bigger) usage examples, API doc...

# figures/tape.jpeg http://pixorblog.files.wordpress.com/2020/01/tape.jpeg
# ./figures/tape.jpeg http://pixorblog.files.wordpress.com/2020/01/tape-1.jpeg

* API Documentation

Again, even if the library supports higher order derivatives it is
optimized for the first order derivatives.

** AD types

These are the types you must use when you want to compute derivatives.
- =AD<T>= for first order derivatives
- =AD<AD<T>>= for second order derivatives
- ...

** Tape 

A =local_thread= is globally stored. You can access it by:

#+BEGIN_SRC cpp :eval never 

tape<T>();          // returns a reference Tape<T>& to the tape associated to AD<T>
tape<AD<T>>();      // returns a reference Tape<T>& to the tape associated to AD<AD<T>>
tape<AD<AD<T>>>();  // returns a reference Tape<T>& to the tape associated to AD<AD<AD<T>>>
                    // etc...
#+END_SRC

